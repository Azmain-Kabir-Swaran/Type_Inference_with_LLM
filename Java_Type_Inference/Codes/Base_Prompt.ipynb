{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/home/azmain/alljavajsons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFiles = []\n",
    "correctOutputFiles = []\n",
    "    \n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "for file in sorted(glob.glob(\"*.java.json\"), key=numericalSort):\n",
    "    inputFiles.append(file)\n",
    "\n",
    "for file in sorted(glob.glob(\"*.benchmark_log.json\"), key=numericalSort):\n",
    "    correctOutputFiles.append(file)\n",
    "\n",
    "print(inputFiles)\n",
    "print('\\n\\n\\n')\n",
    "print(correctOutputFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codes(inputFiles):\n",
    "    codes = []\n",
    "    for code in inputFiles:\n",
    "        codes.append(str(json.load(open(code))['originalContent']))\n",
    "\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_outputs(correctOutputFiles):\n",
    "    correct_outputs = []\n",
    "    for output in correctOutputFiles:\n",
    "        correct_output_list = json.load(open(output))['total_imports']\n",
    "        correct_output_list = [\"import \"+i+\";\" for i in correct_output_list]\n",
    "        correct_outputs.append(correct_output_list)\n",
    "    \n",
    "    for import_lines in correct_outputs:\n",
    "        if \"import gen.R;\" in import_lines:\n",
    "            import_lines.remove(\"import gen.R;\")\n",
    "\n",
    "    return correct_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(codes, correct_outputs):\n",
    "    dataset = {\n",
    "        \"codes\": codes,\n",
    "        \"correct_outputs\": correct_outputs\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_examples_and_y_true(dataset):\n",
    "    sample_list = []\n",
    "\n",
    "    for i in range(0, len(dataset[\"codes\"])):\n",
    "        sample_list.append(dict(codes=dataset[\"codes\"][i], correct_outputs=dataset[\"correct_outputs\"][i]))\n",
    "    \n",
    "    # print(sample_list)\n",
    "    \n",
    "    test_examples = [(example[\"codes\"], example[\"correct_outputs\"]) for example in sample_list]\n",
    "    y_true = [correct_outputs for _, correct_outputs in test_examples]\n",
    "    \n",
    "    return test_examples, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Android Codes: {}\\n\".format(len(inputFiles[:50])))\n",
    "print(inputFiles[:50])\n",
    "\n",
    "android_codes = get_codes(inputFiles[:50])\n",
    "# print(android_codes)\n",
    "\n",
    "android_correct_outputs = get_correct_outputs(correctOutputFiles[:50])\n",
    "# print(android_correct_outputs)\n",
    "\n",
    "android_dataset = get_dataset(android_codes, android_correct_outputs)\n",
    "# print(android_dataset)\n",
    "\n",
    "android_test_examples, android_y_true = get_test_examples_and_y_true(android_dataset)\n",
    "# print(android_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total JDK Codes: {}\\n\".format(len(inputFiles[50:73])))\n",
    "print(inputFiles[50:73])\n",
    "\n",
    "jdk_codes = get_codes(inputFiles[50:73])\n",
    "# print(jdk_codes)\n",
    "\n",
    "jdk_correct_outputs = get_correct_outputs(correctOutputFiles[50:73])\n",
    "# print(jdk_correct_outputs)\n",
    "\n",
    "jdk_dataset = get_dataset(jdk_codes, jdk_correct_outputs)\n",
    "# print(jdk_dataset)\n",
    "\n",
    "jdk_test_examples, jdk_y_true = get_test_examples_and_y_true(jdk_dataset)\n",
    "# print(jdk_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Hibernate Codes: {}\\n\".format(len(inputFiles[73:74] + inputFiles[174:224])))\n",
    "print(inputFiles[73:74] + inputFiles[174:224])\n",
    "\n",
    "hibernate_codes = get_codes(inputFiles[73:74] + inputFiles[174:224])\n",
    "# print(hibernate_codes)\n",
    "\n",
    "hibernate_correct_outputs = get_correct_outputs(correctOutputFiles[73:74] + correctOutputFiles[174:224])\n",
    "# print(hibernate_correct_outputs)\n",
    "\n",
    "hibernate_dataset = get_dataset(hibernate_codes, hibernate_correct_outputs)\n",
    "# print(hibernate_dataset)\n",
    "\n",
    "hibernate_test_examples, hibernate_y_true = get_test_examples_and_y_true(hibernate_dataset)\n",
    "# print(hibernate_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total JodaTime Codes: {}\\n\".format(len(inputFiles[74:124])))\n",
    "print(inputFiles[74:124])\n",
    "\n",
    "jodatime_codes = get_codes(inputFiles[74:124])\n",
    "# print(jodatime_codes)\n",
    "\n",
    "jodatime_correct_outputs = get_correct_outputs(correctOutputFiles[74:124])\n",
    "# print(jodatime_correct_outputs)\n",
    "\n",
    "jodatime_dataset = get_dataset(jodatime_codes, jodatime_correct_outputs)\n",
    "# print(jodatime_dataset)\n",
    "\n",
    "jodatime_test_examples, jodatime_y_true = get_test_examples_and_y_true(jodatime_dataset)\n",
    "# print(jodatime_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total GWT Codes: {}\\n\".format(len(inputFiles[124:174])))\n",
    "print(inputFiles[124:174])\n",
    "\n",
    "gwt_codes = get_codes(inputFiles[124:174])\n",
    "# print(gwt_codes)\n",
    "\n",
    "gwt_correct_outputs = get_correct_outputs(correctOutputFiles[124:174])\n",
    "# print(gwt_correct_outputs)\n",
    "\n",
    "gwt_dataset = get_dataset(gwt_codes, gwt_correct_outputs)\n",
    "# print(gwt_dataset)\n",
    "\n",
    "gwt_test_examples, gwt_y_true = get_test_examples_and_y_true(gwt_dataset)\n",
    "# print(gwt_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total XStream Codes: {}\\n\".format(len(inputFiles[224:268])))\n",
    "print(inputFiles[224:268])\n",
    "\n",
    "xstream_codes = get_codes(inputFiles[224:268])\n",
    "# print(xstream_codes)\n",
    "\n",
    "xstream_correct_outputs = get_correct_outputs(correctOutputFiles[224:268])\n",
    "# print(xstream_correct_outputs)\n",
    "\n",
    "xstream_dataset = get_dataset(xstream_codes, xstream_correct_outputs)\n",
    "# print(xstream_dataset)\n",
    "\n",
    "xstream_test_examples, xstream_y_true = get_test_examples_and_y_true(xstream_dataset)\n",
    "# print(xstream_test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_imports(predicted_imports):\n",
    "    added_imports = []\n",
    "    for import_group in predicted_imports:\n",
    "        new_group = []\n",
    "        for import_statement in import_group:\n",
    "            new_group.append(import_statement)\n",
    "        added_imports.append(new_group)\n",
    "    \n",
    "    return added_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_imports(save_directory, code_name, list_of_java_codes, list_of_imports):\n",
    "    code_import_dict = {}\n",
    "    # Check if lengths match\n",
    "    if len(list_of_java_codes) != len(list_of_imports):\n",
    "        print(\"Mismatch between number of Java code strings and import lists!\")\n",
    "    else:\n",
    "        # Zip the lists together into a dictionary\n",
    "        code_import_dict = {i: (imports, code) for i, (imports, code) in enumerate(zip(list_of_imports, list_of_java_codes))}\n",
    "\n",
    "    # Prepend the imports to the Java codes, save each to a .java file\n",
    "    for index, (imports, code) in code_import_dict.items():\n",
    "        # Split the code into lines\n",
    "        lines = code.split('\\n')\n",
    "        \n",
    "        # Find the line with the package declaration\n",
    "        package_line_index = next((i for i, line in enumerate(lines) if line.strip().startswith('package ')), None)\n",
    "\n",
    "        # If a package declaration is found, insert the imports after it\n",
    "        if package_line_index is not None:\n",
    "            lines = lines[:package_line_index+1] + imports + lines[package_line_index+1:]\n",
    "        else:\n",
    "            # If not, prepend the imports to the code\n",
    "            lines = imports + lines\n",
    "\n",
    "        full_code = '\\n'.join(lines)\n",
    "        file_name = \"\"\n",
    "        if code_name == \"android\":\n",
    "            if index<9:\n",
    "                file_name = f\"Android0{index+1}.java\"\n",
    "            else:\n",
    "                file_name = f\"Android{index+1}.java\"\n",
    "        elif code_name == \"jdk\":\n",
    "            file_name = f\"Class_{index+1}.java\" \n",
    "        elif code_name == \"hibernate\":\n",
    "            if index == 0:\n",
    "                file_name = f\"HibernateUtil.java\"\n",
    "            else:\n",
    "                file_name = f\"hibernate_class_{index}.java\"\n",
    "        elif code_name == \"jodatime\":\n",
    "            if index<9:\n",
    "                file_name = f\"JodaTime0{index+1}.java\"\n",
    "            else:\n",
    "                file_name = f\"JodaTime{index+1}.java\"\n",
    "        elif code_name == \"gwt\":\n",
    "            file_name = f\"gwt_class_{index+1}.java\"\n",
    "        elif code_name == \"xstream\":\n",
    "            file_name = f\"xstream_class_{index+1}.java\"\n",
    "        full_path = os.path.join(save_directory, file_name)\n",
    "\n",
    "        # Save the full code to a .java file\n",
    "        with open(full_path, \"w\") as f:\n",
    "            f.write(full_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Prompt Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_process(y_pred, y_true):\n",
    "    y_pred_processed = []\n",
    "    y_true_processed = []\n",
    "    \n",
    "    for pred, correct_imports in zip(y_pred, y_true):\n",
    "        max_length = max(len(pred), len(correct_imports))\n",
    "        correct_preds = list(set(pred).intersection(correct_imports))\n",
    "#         print('Correct Predictions:', correct_preds)\n",
    "#         wrong_preds = max_length - len(correct_preds)\n",
    "#         print('Wrong Predictions:', wrong_preds)\n",
    "\n",
    "        for i in range(0, max_length):\n",
    "            if i<len(correct_preds):\n",
    "                y_pred_processed.append(1)\n",
    "                y_true_processed.append(1)\n",
    "            else:\n",
    "                if i<len(correct_imports):\n",
    "                    y_pred_processed.append(0)\n",
    "                    y_true_processed.append(1)\n",
    "                else:\n",
    "                    y_pred_processed.append(1)\n",
    "                    y_true_processed.append(0)\n",
    "            \n",
    "    print(y_pred_processed)\n",
    "    print(y_true_processed)\n",
    "    print()\n",
    "    return y_pred_processed, y_true_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_performance(y_pred, y_true):\n",
    "    print(json.dumps({\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred)\n",
    "    }, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(code_snippet):\n",
    "    retry_delay = 2\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Reply with only code, no elaboration.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Make the code below compilable:\\n\\n{code_snippet}\"},\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "            )\n",
    "            \n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        except Exception as e:\n",
    "            time.sleep(retry_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(input_string):\n",
    "    pattern = r\"(package|import|@[\\w]+|public|private|protected).*\\}\\s*$\"\n",
    "    match = re.search(pattern, input_string, re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        # print(\"No valid code block found!\")\n",
    "        return \"No valid code block found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(dataset):\n",
    "    y_pred = []\n",
    "    predicted_codes = []\n",
    "    for code_snippet, correct_imports in tqdm(dataset):\n",
    "        predicted_code = extract_code(get_prediction(code_snippet))\n",
    "        predicted_import = re.findall(r\"import\\s+[\\w\\., ]+;\", predicted_code)\n",
    "        y_pred.append(predicted_import)\n",
    "        predicted_codes.append(predicted_code)\n",
    "    return y_pred, predicted_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/home/azmain/code_for_compilation_test/base-prompt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for Android Classes\n",
    "\n",
    "print(\"\\nPrediction for Android Classes:\\n\")\n",
    "y_pred, predicted_codes = get_predictions(android_test_examples)\n",
    "print(\"\\nPredicted Import List:\", y_pred)\n",
    "print(\"\\nCorrect Import List:\", android_y_true)\n",
    "\n",
    "code_name = \"android\"\n",
    "codes = predicted_codes\n",
    "predicted_imports = y_pred\n",
    "import_list = group_imports(predicted_imports)\n",
    "append_imports(save_directory, code_name, codes, import_list)\n",
    "\n",
    "y_pred_processed, y_true_processed = pred_process(y_pred, android_y_true)\n",
    "eval_performance(y_pred_processed, y_true_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for JDK Classes\n",
    "\n",
    "print(\"\\nPrediction for JDK Classes:\\n\")\n",
    "y_pred, predicted_codes = get_predictions(jdk_test_examples)\n",
    "print(\"\\nPredicted Import List:\", y_pred)\n",
    "print(\"\\nCorrect Import List:\", jdk_y_true)\n",
    "\n",
    "code_name = \"jdk\"\n",
    "codes = predicted_codes\n",
    "predicted_imports = y_pred\n",
    "import_list = group_imports(predicted_imports)\n",
    "append_imports(save_directory, code_name, codes, import_list)\n",
    "\n",
    "y_pred_processed, y_true_processed = pred_process(y_pred, jdk_y_true)\n",
    "eval_performance(y_pred_processed, y_true_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for Hibernate Classes\n",
    "\n",
    "print(\"\\nPrediction for Hibernate Classes:\\n\")\n",
    "y_pred, predicted_codes = get_predictions(hibernate_test_examples)\n",
    "print(\"\\nPredicted Import List:\", y_pred)\n",
    "print(\"\\nCorrect Import List:\", hibernate_y_true)\n",
    "\n",
    "code_name = \"hibernate\"\n",
    "codes = predicted_codes\n",
    "predicted_imports = y_pred\n",
    "import_list = group_imports(predicted_imports)\n",
    "append_imports(save_directory, code_name, codes, import_list)\n",
    "\n",
    "y_pred_processed, y_true_processed = pred_process(y_pred, hibernate_y_true)\n",
    "eval_performance(y_pred_processed, y_true_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for Joda-Time Classes\n",
    "\n",
    "print(\"\\nPrediction for Joda-Time Classes:\\n\")\n",
    "y_pred, predicted_codes = get_predictions(jodatime_test_examples)\n",
    "print(\"\\nPredicted Import List:\", y_pred)\n",
    "print(\"\\nCorrect Import List:\", jodatime_y_true)\n",
    "\n",
    "code_name = \"jodatime\"\n",
    "codes = predicted_codes\n",
    "predicted_imports = y_pred\n",
    "import_list = group_imports(predicted_imports)\n",
    "append_imports(save_directory, code_name, codes, import_list)\n",
    "\n",
    "y_pred_processed, y_true_processed = pred_process(y_pred, jodatime_y_true)\n",
    "eval_performance(y_pred_processed, y_true_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for GWT Classes\n",
    "\n",
    "print(\"\\nPrediction for GWT Classes:\\n\")\n",
    "y_pred, predicted_codes = get_predictions(gwt_test_examples)\n",
    "print(\"\\nPredicted Import List:\", y_pred)\n",
    "print(\"\\nCorrect Import List:\", gwt_y_true)\n",
    "\n",
    "code_name = \"gwt\"\n",
    "codes = predicted_codes\n",
    "predicted_imports = y_pred\n",
    "import_list = group_imports(predicted_imports)\n",
    "append_imports(save_directory, code_name, codes, import_list)\n",
    "\n",
    "y_pred_processed, y_true_processed = pred_process(y_pred, gwt_y_true)\n",
    "eval_performance(y_pred_processed, y_true_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for XStream Classes\n",
    "\n",
    "print(\"\\nPrediction for XStream Classes\\n\")\n",
    "y_pred, predicted_codes = get_predictions(xstream_test_examples)\n",
    "print(\"\\nPredicted Import List:\", y_pred)\n",
    "print(\"\\nCorrect Import List:\", xstream_y_true)\n",
    "\n",
    "code_name = \"xstream\"\n",
    "codes = predicted_codes\n",
    "predicted_imports = y_pred\n",
    "import_list = group_imports(predicted_imports)\n",
    "append_imports(save_directory, code_name, codes, import_list)\n",
    "\n",
    "y_pred_processed, y_true_processed = pred_process(y_pred, xstream_y_true)\n",
    "eval_performance(y_pred_processed, y_true_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_java(file_path, class_path, log_folder_success, log_folder_fail, output_folder):\n",
    "    r_errors_count = 0\n",
    "    gen_r_errors_count = 0\n",
    "    try:\n",
    "        successful_compile = False\n",
    "        # If the output directory doesn't exist, create it\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        \n",
    "        # Compile the .java file with the provided class_path and specify the output directory for .class files\n",
    "        result = subprocess.run(['javac', '-cp', class_path, '-d', output_folder, file_path], capture_output=True, text=True, timeout=10)\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Successfully compiled \\\"{file_path}\\\".\")\n",
    "            stderr_log = result.stderr\n",
    "            successful_compile = True\n",
    "        else:\n",
    "            warning_val = False\n",
    "            num_errors = 1\n",
    "            stderr_lines = result.stderr.splitlines()\n",
    "            num_errors_line = stderr_lines[-1]\n",
    "            try:\n",
    "                num_errors = int(num_errors_line.split()[0])  # Extract the number of error(s)\n",
    "            except ValueError:\n",
    "                warning_val = True\n",
    "\n",
    "            r_errors_count = result.stderr.count(\"error: package R does not exist\")\n",
    "            gen_r_errors_count = result.stderr.count(\"error: package gen does not exist\")\n",
    "            total_r_errors_count = r_errors_count + gen_r_errors_count\n",
    "\n",
    "            # Check if all errors are related to \"package R does not exist\"\n",
    "            if num_errors == total_r_errors_count and warning_val == False:\n",
    "                print(f\"Successfully compiled, ignoring {num_errors} 'package R does not exist' errors for \\\"{file_path}\\\".\")\n",
    "                stderr_log = \"No error (Ignored 'package R does not exist' errors)\"\n",
    "                successful_compile = True\n",
    "            else:\n",
    "                if warning_val:\n",
    "                    print(f\"Compiled with warning.\")\n",
    "                    stderr_log = \"Warning present\"\n",
    "                    successful_compile = True\n",
    "                else:\n",
    "                    print(f\"Failed to compile \\\"{file_path}\\\".\")\n",
    "                    stderr_log = result.stderr\n",
    "                    successful_compile = False\n",
    "\n",
    "        # Read the content of the Java file\n",
    "        with open(file_path, 'r', errors='ignore') as java_file:\n",
    "            java_code = java_file.read()\n",
    "\n",
    "        # Prepare the JSON log\n",
    "        log_data = {\n",
    "            \"file\": file_path,\n",
    "            \"java_code\": java_code,\n",
    "            \"stdout\": result.stdout,\n",
    "            \"stderr\": stderr_log,\n",
    "            \"return_code\": result.returncode\n",
    "        }\n",
    "        \n",
    "        # Save the logs to a file named after the Java file being compiled\n",
    "        log_file_name = os.path.basename(file_path).replace('.java', '.json')\n",
    "        if successful_compile:\n",
    "            log_file_path = os.path.join(log_folder_success, log_file_name)\n",
    "        else:\n",
    "            log_file_path = os.path.join(log_folder_fail, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, 'w') as log_file:\n",
    "            json.dump(log_data, log_file, indent=4)\n",
    "\n",
    "        return successful_compile\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Compilation of {file_path} timed out.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_success_rate(directory, class_path, log_folder_success, log_folder_fail, output_folder):\n",
    "    if not os.path.exists(log_folder_success):\n",
    "        os.makedirs(log_folder_success)\n",
    "\n",
    "    if not os.path.exists(log_folder_fail):\n",
    "        os.makedirs(log_folder_fail)\n",
    "\n",
    "    java_files = [f for f in os.listdir(directory) if f.endswith('.java')]\n",
    "    if not java_files:\n",
    "        print(\"No .java files found.\")\n",
    "        return 0\n",
    "\n",
    "    total_files = len(java_files)\n",
    "    successful_compilations = 0\n",
    "\n",
    "    for java_file in java_files:\n",
    "        file_path = os.path.join(directory, java_file)\n",
    "        if compile_java(file_path, class_path, log_folder_success, log_folder_fail, output_folder):\n",
    "            successful_compilations += 1\n",
    "\n",
    "    success_rate = (successful_compilations / total_files) * 100\n",
    "    return success_rate, successful_compilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_type = \"base-prompt\"\n",
    "dir_path = f\"/home/azmain/code_for_compilation_test/{dir_type}/\"\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/{dir_type}-logs/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/{dir_type}-logs/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/compiled-classes/{dir_type}-compiled/\" \n",
    "\n",
    "rate, num_successful = calculate_success_rate(dir_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "print(f\"Compilation success rate: {rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {num_successful}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azmain_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

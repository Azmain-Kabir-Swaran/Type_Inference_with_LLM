{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imports(code):\n",
    "    return re.findall(r\"(import .*?;)\", code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for numerical sort\n",
    "def numericalSort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_imports(outputFiles):\n",
    "    correct_outputs = []\n",
    "    for output in outputFiles:\n",
    "        correct_output_list = json.load(open(output))['total_imports']\n",
    "        correct_output_list = [\"import \"+i+\";\" for i in correct_output_list]\n",
    "        correct_outputs.append(correct_output_list)\n",
    "\n",
    "    for import_lines in correct_outputs:\n",
    "        if \"import gen.R;\" in import_lines:\n",
    "            import_lines.remove(\"import gen.R;\")\n",
    "\n",
    "    return correct_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"/home/azmain/snr_all_json/\"\n",
    "os.chdir(source_path)\n",
    "\n",
    "outputFiles = []\n",
    "\n",
    "all_files = glob.glob(os.path.join(source_path, \"*.benchmark_log.json\"))\n",
    "\n",
    "filtered_files = [f for f in all_files if \"HibernateUtil\" not in os.path.basename(f)]\n",
    "\n",
    "sorted_files = sorted(filtered_files, key=numericalSort)\n",
    "\n",
    "for file in sorted_files:\n",
    "    outputFiles.append(file)\n",
    "\n",
    "true_list = get_correct_imports(outputFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_import_statements(predicted_list, true_list):\n",
    "    if len(predicted_list) != len(true_list):\n",
    "        print(\"The two lists must have the same length.\")\n",
    "\n",
    "    counts = {\n",
    "        \"Same\": 0,\n",
    "        \"Different\": 0,\n",
    "        \"Extra\": 0,\n",
    "        \"Missing\": 0,\n",
    "        \"None\": 0\n",
    "    }\n",
    "\n",
    "    for predicted, ground_truth in zip(predicted_list, true_list):\n",
    "        predicted_set = set(predicted)\n",
    "        ground_truth_set = set(ground_truth)\n",
    "\n",
    "        if predicted_set == ground_truth_set:\n",
    "            counts[\"Same\"] += 1\n",
    "        elif not predicted_set:\n",
    "            counts[\"None\"] += 1\n",
    "        elif predicted_set.issubset(ground_truth_set):\n",
    "            counts[\"Missing\"] += 1\n",
    "        elif predicted_set.issuperset(ground_truth_set):\n",
    "            counts[\"Extra\"] += 1\n",
    "        else:\n",
    "            counts[\"Different\"] += 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_calc(source_path):\n",
    "    os.chdir(source_path)\n",
    "\n",
    "    all_files = glob.glob(os.path.join(source_path, \"*.json\"))\n",
    "\n",
    "    # Filter out the \"HibernateUtil\" file based on the filename\n",
    "    filtered_files = [f for f in all_files if \"HibernateUtil\" not in os.path.basename(f)]\n",
    "\n",
    "\n",
    "    sorted_files = sorted(filtered_files, key=numericalSort)\n",
    "    predicted_list = []\n",
    "\n",
    "    # From JSON file\n",
    "    for filepath in sorted_files:\n",
    "        with open(filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            java_code = data.get(\"java_code\", \"\")\n",
    "            imports = extract_imports(java_code)\n",
    "            \n",
    "            predicted_list.append(imports)\n",
    "\n",
    "    result = compare_import_statements(predicted_list, true_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For SnR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SnR:\n",
      "\n",
      "{'Same': 143, 'Different': 78, 'Extra': 4, 'Missing': 35, 'None': 7}\n"
     ]
    }
   ],
   "source": [
    "# For SnR\n",
    "\n",
    "print(\"For SnR:\\n\")\n",
    "\n",
    "source_path = \"/home/azmain/snr_fixed/\"\n",
    "os.chdir(source_path)\n",
    "\n",
    "all_files = glob.glob(os.path.join(source_path, \"*.java\"))\n",
    "\n",
    "# Filter out the \"HibernateUtil\" file based on the filename\n",
    "filtered_files = [f for f in all_files if \"HibernateUtil\" not in os.path.basename(f)]\n",
    "\n",
    "\n",
    "sorted_files = sorted(filtered_files, key=numericalSort)\n",
    "predicted_list = []\n",
    "\n",
    "# From .java file\n",
    "for filepath in sorted_files:\n",
    "    with open(filepath, 'r') as file:\n",
    "        java_code = file.read()  # assuming the java file is plain text and not in JSON format\n",
    "        imports = extract_imports(java_code)\n",
    "        predicted_list.append(imports)\n",
    "\n",
    "result = compare_import_statements(predicted_list, true_list)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Base Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Base Prompt:\n",
      "\n",
      "{'Same': 173, 'Different': 55, 'Extra': 14, 'Missing': 19, 'None': 6}\n"
     ]
    }
   ],
   "source": [
    "# For Base Prompt\n",
    "\n",
    "print(\"For Base Prompt:\\n\")\n",
    "source_path = \"/home/azmain/GitHub Codes/base_prompt_combined_logs/\"\n",
    "print(result_calc(source_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Zero-shot Self-consistency with 10 sample 5 attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Zero-shot Self-consistency with 10 sample 5 attempt:\n",
      "\n",
      "{'Same': 202, 'Different': 35, 'Extra': 16, 'Missing': 14, 'None': 0}\n"
     ]
    }
   ],
   "source": [
    "# For Zero-shot Self-consistency with 10 sample 5 attempt\n",
    "\n",
    "print(\"For Zero-shot Self-consistency with 10 sample 5 attempt:\\n\")\n",
    "source_path = \"/home/azmain/GitHub Codes/zero-shot_self_c_10_sample_5_attempt_combined/\"\n",
    "print(result_calc(source_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Zero-shot Self-consistency from 10 Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Zero-shot Self-consistency from 10 Sample:\n",
      "\n",
      "{'Same': 191, 'Different': 48, 'Extra': 14, 'Missing': 12, 'None': 2}\n"
     ]
    }
   ],
   "source": [
    "# For Zero-shot Self-consistency from 10 Sample\n",
    "\n",
    "print(\"For Zero-shot Self-consistency from 10 Sample:\\n\")\n",
    "source_path = \"/home/azmain/GitHub Codes/zero_shot_combined_logs/\"\n",
    "print(result_calc(source_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Zero-shot without Self-consistency (temp 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Zero-shot without Self-consistency (temp 0.5):\n",
      "\n",
      "{'Same': 180, 'Different': 58, 'Extra': 14, 'Missing': 14, 'None': 1}\n"
     ]
    }
   ],
   "source": [
    "# For Zero-shot without Self-consistency (temp 0.5)\n",
    "\n",
    "print(\"For Zero-shot without Self-consistency (temp 0.5):\\n\")\n",
    "source_path = \"/home/azmain/GitHub Codes/temp_0.5_no_self_c_combined_logs/\"\n",
    "print(result_calc(source_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Source SO Dataset with Compile Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Source SO Dataset with Compile Fixing:\n",
      "\n",
      "{'Same': 175, 'Different': 48, 'Extra': 22, 'Missing': 19, 'None': 3}\n"
     ]
    }
   ],
   "source": [
    "# For Source SO Dataset with Compile Fixing\n",
    "\n",
    "print(\"For Source SO Dataset with Compile Fixing:\\n\")\n",
    "source_path = \"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/all_so_logs/\"\n",
    "print(result_calc(source_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azmain_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

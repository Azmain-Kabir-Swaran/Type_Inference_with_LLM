{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = 'gpt-3.5-turbo'\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refined_error_log(stderr):\n",
    "    # Modify stderr to only include the .java, not the full file path\n",
    "    refined_stderr = '\\n'.join([line.split('/')[-1] if '.java' in line else line for line in stderr.split('\\n')])\n",
    "\n",
    "    return refined_stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(input_string):\n",
    "    pattern = r\"(package|import|@[\\w]+|public|private|protected).*\\}\\s*$\"\n",
    "    match = re.search(pattern, input_string, re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(0)  # get the entire matched string\n",
    "    else:\n",
    "        print(\"No valid code block found!\")\n",
    "        return \"No valid code block found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_code(java_code, refined_stderr, attempt, chat_history, chat_history_code):\n",
    "    message_content = \"\"\n",
    "    main_prompt = \"Now fix the error only by fixing the import statements by not using wildcard imports and must not modify code body which means do not change anything inside the class. So, it can be successfully compiled and reply with full code.\"\n",
    "    if attempt < 2:\n",
    "        message_content = f\"See the code below:\\n\\\"\\\"\\\"\\n{java_code}\\n\\\"\\\"\\\"\\nFor the above code I got the below error log:\\n\\\"\\\"\\\"\\n{refined_stderr}\\n\\\"\\\"\\\"\\n{main_prompt}\"\n",
    "        if len(encoding.encode(message_content)) > 4000:\n",
    "            message_content = f\"{java_code}\\n\\\"\\\"\\\"\\n{main_prompt}\"\n",
    "            if len(encoding.encode(message_content)) > 4000:\n",
    "                return \"0\", message_content\n",
    "            \n",
    "    else:\n",
    "        message_content = f\"{chat_history}{main_prompt}\"\n",
    "        if len(encoding.encode(message_content)) > 4000:\n",
    "            if chat_history_code != \"\":\n",
    "                message_content = f\"{chat_history_code}\\n\\\"\\\"\\\"\\n{main_prompt}\"\n",
    "                if len(encoding.encode(message_content)) > 4000:\n",
    "                    return \"0\"\n",
    "            else:\n",
    "                return \"0\", message_content\n",
    "            \n",
    "    retry_delay = 2\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Reply with only code, no elaboration.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"{message_content}\"},\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "            )\n",
    "            \n",
    "            return extract_code(response[\"choices\"][0][\"message\"][\"content\"]), message_content\n",
    "        \n",
    "        except Exception as e:\n",
    "            time.sleep(retry_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_error_message = \"\"\n",
    "\n",
    "def compile_java(attempt, used_prompt, new_java_code_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path):\n",
    "    try:\n",
    "        is_compile_success = False\n",
    "        # If the output directory doesn't exist, create it\n",
    "        if not os.path.exists(compiled_folder_path):\n",
    "            os.makedirs(compiled_folder_path)\n",
    "        \n",
    "        # Compile the .java file with the provided class_path and specify the output directory for .class files\n",
    "        result = subprocess.run(['javac', '-cp', class_path, '-d', compiled_folder_path, new_java_code_path], capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Attempt {attempt}. Successfully compiled \\\"{new_java_code_path}\\\".\")\n",
    "            stderr_log = result.stderr\n",
    "            is_compile_success = True\n",
    "        else:\n",
    "            warning_val = False\n",
    "            num_errors = 1\n",
    "            stderr_lines = result.stderr.splitlines()\n",
    "            num_errors_line = stderr_lines[-1]\n",
    "            try:\n",
    "                num_errors = int(num_errors_line.split()[0])  # Extract the number of error(s)\n",
    "            except ValueError:\n",
    "                warning_val = True\n",
    "\n",
    "            r_errors_count = result.stderr.count(\"error: package R does not exist\")\n",
    "\n",
    "            # Check if all errors are related to \"package R does not exist\"\n",
    "            if num_errors == r_errors_count and warning_val == False:\n",
    "                print(f\"Attempt {attempt}. Successfully compiled, ignoring {num_errors} 'package R does not exist' errors for \\\"{new_java_code_path}\\\".\")\n",
    "                stderr_log = \"No error (Ignored 'package R does not exist' errors)\"\n",
    "                is_compile_success = True\n",
    "            else:\n",
    "                if warning_val:\n",
    "                    print(f\"Attempt {attempt}. Compiled with warning.\")\n",
    "                    stderr_log = \"Warning present\"\n",
    "                    is_compile_success = True\n",
    "                else:\n",
    "                    print(f\"Attempt {attempt}. Failed to compile \\\"{new_java_code_path}\\\".\")\n",
    "                    stderr_log = result.stderr\n",
    "                    global chat_history_error_message\n",
    "                    chat_history_error_message = '\\n'.join([line.split('/')[-1] if '.java' in line else line for line in result.stderr.split('\\n')])\n",
    "                    is_compile_success = False\n",
    "\n",
    "        # Read the content of the Java file\n",
    "        with open(new_java_code_path, 'r') as java_file:\n",
    "            java_code = java_file.read()\n",
    "        # Prepare the JSON log\n",
    "        log_data = {\n",
    "            \"attempt\": attempt,\n",
    "            \"file\": new_java_code_path,\n",
    "            \"java_code\": java_code,\n",
    "            \"used_prompt\": used_prompt,\n",
    "            \"stdout\": result.stdout,\n",
    "            \"stderr\": stderr_log,\n",
    "            \"return_code\": result.returncode\n",
    "        }\n",
    "\n",
    "        if is_compile_success or (not is_compile_success and attempt == max_attempt):\n",
    "        \n",
    "            # Save the logs to a json file named after the Java file being compiled\n",
    "            base_name = os.path.basename(new_java_code_path).replace('.java', '')\n",
    "            log_file_name = f\"{base_name}_attempt_{attempt}.json\"\n",
    "            if is_compile_success:\n",
    "                log_file_path = os.path.join(log_folder_success, log_file_name)\n",
    "            else:\n",
    "                log_file_path = os.path.join(log_folder_fail, log_file_name)\n",
    "            \n",
    "            stringified_data = {str(key): value for key, value in log_data.items()}\n",
    "            with open(log_file_path, 'w') as log_file:\n",
    "                json.dump(stringified_data, log_file, indent=4)\n",
    "        else:\n",
    "            # Save the logs to a txt file named after the Java file being compiled\n",
    "            base_name = os.path.basename(new_java_code_path).replace('.java', '')\n",
    "            log_file_name = f\"{base_name}_attempt_{attempt}.txt\"\n",
    "            \n",
    "            log_file_path = os.path.join(log_folder_fail, log_file_name)\n",
    "            \n",
    "            with open(log_file_path, 'w') as log_file:\n",
    "                for key, value in log_data.items():\n",
    "                    if key == \"java_code\" or key == \"used_prompt\":\n",
    "                        if isinstance(value, str):\n",
    "                            log_file.write(f\"\\\"{key}\\\": \\\"\\n\\n{value}\\n\\\"\\n\\n\")\n",
    "                        else:\n",
    "                            log_file.write(f\"\\\"{key}\\\": {value}\\n\\n\")\n",
    "                    else:\n",
    "                        if isinstance(value, str):\n",
    "                            log_file.write(f\"\\\"{key}\\\": \\\"{value}\\\"\\n\\n\")\n",
    "                        else:\n",
    "                            log_file.write(f\"\\\"{key}\\\": {value}\\n\\n\")\n",
    "\n",
    "        return is_compile_success\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Compilation of {new_java_code_path} timed out.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path):\n",
    "    java_code_path = data[\"file\"]\n",
    "    java_code = data[\"java_code\"]\n",
    "    refined_stderr = get_refined_error_log(data[\"stderr\"])\n",
    "    \n",
    "    if not os.path.exists(log_folder_success):\n",
    "        os.makedirs(log_folder_success)\n",
    "\n",
    "    if not os.path.exists(log_folder_fail):\n",
    "        os.makedirs(log_folder_fail)\n",
    "    \n",
    "    # Maximum tries to get a successful compilation\n",
    "    chat_history = \"\"\n",
    "    chat_history_code = \"\"\n",
    "    fixed_code = \"\"\n",
    "    global chat_history_error_message\n",
    "    chat_history_error_message = \"\"\n",
    "                           \n",
    "    for i in range(max_attempt):\n",
    "        attempt = i+1\n",
    "        if i==0:\n",
    "            fixed_code, used_prompt = get_fixed_code(java_code, refined_stderr, attempt, chat_history, chat_history_code)\n",
    "        else:\n",
    "            # Keeping the last fixed code by the model inside java_code\n",
    "            java_code = fixed_code\n",
    "            chat_history = f\"{chat_history}{chat_history_code}\\n\\nYou gave the above imports fix in your attempt {i}. But compiler gave this error:\\n\\n{chat_history_error_message}\\n\\n\"\n",
    "            if len(encoding.encode(chat_history)) > 4000:\n",
    "                last_chat_history = f\"{chat_history_code}\\n\\nYou gave the above imports fix. But compiler gave this error:\\n\\n{chat_history_error_message}\\n\\n\"\n",
    "                fixed_code, used_prompt = get_fixed_code(java_code, refined_stderr, attempt, last_chat_history, chat_history_code)\n",
    "            else:\n",
    "                fixed_code, used_prompt = get_fixed_code(java_code, refined_stderr, attempt, chat_history, chat_history_code)\n",
    "        \n",
    "        if fixed_code == \"0\":\n",
    "            fixed_code = java_code\n",
    "            \n",
    "        chat_history_code = fixed_code\n",
    "        # Saving the predicted fixed code by the model\n",
    "        new_java_file_name = java_code_path.split('/')[-1]\n",
    "        new_java_code_path = os.path.join(fixed_path, new_java_file_name)\n",
    "        with open(new_java_code_path, 'w') as file:\n",
    "            file.write(fixed_code)\n",
    "        if compile_java(attempt, used_prompt, new_java_code_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path):\n",
    "            return 1\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot Self-consistency from 10 Sample 5 Attempts\n",
    "\n",
    "max_attempt = 5\n",
    "dir_type = \"zero-shot\"\n",
    "\n",
    "existing_failed_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/{dir_type}-logs/compile_fail\"\n",
    "fixed_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/{dir_type}-fix/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/{dir_type}-logs/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/{dir_type}-logs/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/{dir_type}-compiled/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot Self-consistency from 10 Sample 10 Attempts\n",
    "\n",
    "max_attempt = 10\n",
    "dir_type = \"10-attempt\"\n",
    "\n",
    "existing_failed_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/zero-shot-logs/compile_fail\"\n",
    "fixed_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/zero-shot-{dir_type}/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/zero-shot-{dir_type}/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot Self-consistency from 10 Sample 15 Attempts\n",
    "\n",
    "max_attempt = 15\n",
    "dir_type = \"15-attempt\"\n",
    "\n",
    "existing_failed_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/zero-shot-logs/compile_fail\"\n",
    "fixed_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/zero-shot-{dir_type}/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/zero-shot-{dir_type}/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot Self-consistency from 20 Sample 5 Attempts\n",
    "\n",
    "max_attempt = 5\n",
    "dir_type = \"from-20-sample\"\n",
    "\n",
    "existing_failed_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/zero-shot-logs/{dir_type}/compile_fail/\"\n",
    "fixed_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/zero-shot-{dir_type}/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/zero-shot-{dir_type}/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot Self-consistency from 30 Sample 5 Attempts\n",
    "\n",
    "max_attempt = 5\n",
    "dir_type = \"from-30-sample\"\n",
    "\n",
    "existing_failed_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/zero-shot-logs/{dir_type}/compile_fail/\"\n",
    "fixed_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/zero-shot-{dir_type}/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/zero-shot-{dir_type}/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/zero-shot-{dir_type}/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-shot Self-consistency with Semantic Similarity from 10 Sample 5 Attempts\n",
    "\n",
    "max_attempt = 5\n",
    "dir_type = \"one-shot\"\n",
    "\n",
    "existing_failed_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/logs/{dir_type}-logs/compile_fail\"\n",
    "fixed_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/{dir_type}-fix/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/{dir_type}-logs/compile_success/\"\n",
    "log_folder_fail = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/{dir_type}-logs/compile_fail/\"\n",
    "compiled_folder_path = f\"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/{dir_type}-compiled/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SO Dataset Conversation Fixing\n",
    "\n",
    "max_attempt = 5\n",
    "\n",
    "existing_failed_folder_path = \"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/so_dataset_logs/compile_fail/\"\n",
    "fixed_path = \"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/fixed_codes/so-fix/\"\n",
    "\n",
    "jar_path = f\"/home/azmain/snr_jars/\"\n",
    "class_path = f\".:{jar_path}/*\"\n",
    "log_folder_success = \"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/so-logs/compile_success/\"\n",
    "log_folder_fail = \"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-logs/so-logs/compile_fail/\"\n",
    "compiled_folder_path = \"/home/azmain/GitHub Codes/Type_Inference_with_LLM/Java_Type_Inference/Results/llm_fixes/llm-compiled-classes/so-compiled/\" \n",
    "\n",
    "successful_compilations = 0\n",
    "for filename in os.listdir(existing_failed_folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(existing_failed_folder_path, filename), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            success_count = compile_code_and_result(data, fixed_path, class_path, log_folder_success, log_folder_fail, compiled_folder_path)\n",
    "            successful_compilations += success_count\n",
    "            print()\n",
    "\n",
    "total_files = len([f for f in os.listdir(existing_failed_folder_path) if f.endswith(\".json\")])\n",
    "success_rate = (successful_compilations / total_files) * 100\n",
    "\n",
    "print(f\"Compilation success rate: {success_rate:.2f}%\")\n",
    "print(f\"Number of successfully compiled files: {successful_compilations} out of {total_files}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
